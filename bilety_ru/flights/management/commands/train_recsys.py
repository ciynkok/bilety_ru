from django.core.management.base import BaseCommand
from django.conf import settings
import os
import pandas as pd
import torch
from torch import nn
from torch.utils.data import DataLoader, Dataset
import numpy as np
from tqdm import tqdm

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
from flights.recsys.model_stub import RecModelForInference


class Command(BaseCommand):
    help = "–û–±—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö CSV-—Ñ–∞–π–ª–æ–≤ (bookings.csv –∏ items.csv)."

    def add_arguments(self, parser):
        parser.add_argument(
            "--bookings",
            type=str,
            default=os.path.join(settings.BASE_DIR, "recsys_data", "bookings.csv"),
            help="–ü—É—Ç—å –∫ bookings.csv",
        )
        parser.add_argument(
            "--items",
            type=str,
            default=os.path.join(settings.BASE_DIR, "recsys_data", "offers.csv"),
            help="–ü—É—Ç—å –∫ offers.csv",
        )
        parser.add_argument(
            "--out",
            type=str,
            default=os.path.join(settings.BASE_DIR, "recsys_model.pth"),
            help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏",
        )
        parser.add_argument("--epochs", type=int, default=3, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è")
        parser.add_argument("--batch-size", type=int, default=256, help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞")
        parser.add_argument("--max-len", type=int, default=30, help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

    def handle(self, *args, **options):
        
        class BookingsSeqDataset(Dataset):
            def __init__(self, bookings_csv, items_csv, max_len=30):
                bk = pd.read_csv(bookings_csv)
                items = pd.read_csv(items_csv)

                self.item_ids = items['item_id'].astype(int).tolist()
                self.item2idx = {iid: i for i, iid in enumerate(self.item_ids)}
                self.num_items = len(self.item2idx)
                self.PAD_IDX = self.num_items
                self.max_len = max_len

                self.user_seqs = []
                for uid, g in bk.sort_values('created_at').groupby('user_id'):
                    seq = [self.item2idx[i] for i in g['offer_id'].astype(int).tolist() if int(i) in self.item2idx]
                    if len(seq) < 2:
                        continue
                    self.user_seqs.append(seq)

            def __len__(self):
                return len(self.user_seqs)

            def __getitem__(self, idx):
                seq = self.user_seqs[idx]
                cut = np.random.randint(1, len(seq))
                src = seq[:cut]
                tgt = seq[cut]
                if len(src) > self.max_len:
                    src = src[-self.max_len:]
                pad = [self.PAD_IDX] * (self.max_len - len(src))
                src_padded = pad + src
                return torch.LongTensor(src_padded), torch.LongTensor([tgt])
            
            
        bookings_path = options["bookings"]
        items_path = options["items"]
        out_path = options["out"]
        epochs = options["epochs"]
        batch_size = options["batch_size"]
        max_len = options["max_len"]
        #print(items_path)

        if not os.path.exists(bookings_path) or not os.path.exists(items_path):
            self.stderr.write("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã CSV-—Ñ–∞–π–ª—ã. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ export_booking_data.")
            return

        self.stdout.write(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑:\n  {bookings_path}\n  {items_path}")

        ds = BookingsSeqDataset(bookings_path, items_path, max_len=max_len)
        loader = DataLoader(ds, batch_size=batch_size, shuffle=True)

        model = RecModelForInference(num_items=ds.num_items, max_len=max_len)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)

        opt = torch.optim.Adam(model.parameters(), lr=1e-3)
        crit = nn.CrossEntropyLoss()

        for epoch in range(1, epochs + 1):
            model.train()
            pbar = tqdm(loader, desc=f"–≠–ø–æ—Ö–∞ {epoch}")
            total_loss = 0.0
            for src, tgt in pbar:
                src = src.to(device)
                tgt = tgt.squeeze(1).to(device)
                logits = model(src)
                loss = crit(logits, tgt)
                opt.zero_grad()
                loss.backward()
                opt.step()
                total_loss += loss.item()
                pbar.set_postfix(loss=total_loss / len(loader))

            self.stdout.write(f"–≠–ø–æ—Ö–∞ {epoch} –∑–∞–≤–µ—Ä—à–µ–Ω–∞, —Å—Ä–µ–¥–Ω–∏–π loss = {total_loss/len(loader):.4f}")

        torch.save(model.state_dict(), out_path)
        self.stdout.write(self.style.SUCCESS(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {out_path}"))